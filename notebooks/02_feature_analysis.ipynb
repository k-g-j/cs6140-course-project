{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "matplotlib.use('Agg')  # Use non-interactive backend for PDF export\n",
    "\n",
    "# Set up the output directory for saving figures\n",
    "notebook_dir = Path().absolute()\n",
    "project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "figures_dir = project_root / 'figures'\n",
    "analysis_dir = figures_dir / 'feature_analysis'\n",
    "analysis_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create directories\n",
    "(figures_dir / 'exploration').mkdir(parents=True, exist_ok=True)\n",
    "(figures_dir / 'feature_analysis').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting styles\n",
    "plt.style.use('bmh')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b3e9e306f74bebfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8b8ef4aaea24cda",
   "metadata": {},
   "source": [
    "# Load Processed Data from the Pipeline\n",
    "\n",
    "# Get the current notebook directory and construct the correct path\n",
    "notebook_dir = Path().absolute()\n",
    "project_root = notebook_dir.parent if notebook_dir.name == 'notebooks' else notebook_dir\n",
    "processed_data_path = project_root / 'processed_data' / 'final_processed_data.csv'\n",
    "\n",
    "print(f\"Looking for data file at: {processed_data_path}\")\n",
    "df = pd.read_csv(processed_data_path)\n",
    "\n",
    "# Display basic information about the processed dataset\n",
    "print(\"Dataset Overview:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nShape: {df.shape}\")\n",
    "print(\"\\nFeatures:\")\n",
    "for col in df.columns:\n",
    "    dtype = df[col].dtype\n",
    "    missing = df[col].isnull().sum()\n",
    "    print(f\"- {col}: {dtype} (Missing: {missing})\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2a69635f1b5b15e",
   "metadata": {},
   "source": [
    "# Feature Distribution Analysis\n",
    "def analyze_feature_distributions():\n",
    "    \"\"\"Analyze the distribution of engineered features\"\"\"\n",
    "\n",
    "    # Select numerical columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "    # Create distribution plots\n",
    "    for i in range(0, len(numeric_cols), 3):\n",
    "        cols = numeric_cols[i:i + 3]\n",
    "        fig, axes = plt.subplots(1, len(cols), figsize=(18, 6))\n",
    "        if len(cols) == 1:\n",
    "            axes = [axes]\n",
    "\n",
    "        for ax, col in zip(axes, cols):\n",
    "            sns.histplot(data=df, x=col, ax=ax)\n",
    "            ax.set_title(f'Distribution of {col}')\n",
    "            ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(analysis_dir / f'distribution_group_{i // 3}.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "    # Test for normality\n",
    "    normality_tests = {}\n",
    "    for col in numeric_cols:\n",
    "        stat, p_value = stats.normaltest(df[col].dropna())\n",
    "        normality_tests[col] = {'statistic': stat, 'p_value': p_value}\n",
    "\n",
    "    return pd.DataFrame(normality_tests).T\n",
    "\n",
    "\n",
    "# Run distribution analysis\n",
    "distribution_results = analyze_feature_distributions()\n",
    "print(\"\\nNormality Test Results:\")\n",
    "display(distribution_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5b6877aa0a1a119d",
   "metadata": {},
   "source": [
    "# Correlation Analysis\n",
    "def analyze_correlations():\n",
    "    \"\"\"Analyze correlations between features\"\"\"\n",
    "\n",
    "    # Filter out non-numerical columns\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    df_numerical = df[numerical_cols]\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrix = df_numerical.corr()\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "    plt.title('Feature Correlation Matrix')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(analysis_dir / 'correlation_matrix.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Identify highly correlated features\n",
    "    high_corr = np.where(np.abs(corr_matrix) > 0.8)\n",
    "    high_corr = [(corr_matrix.index[x], corr_matrix.columns[y], corr_matrix.iloc[x, y])\n",
    "                 for x, y in zip(*high_corr) if x != y]\n",
    "\n",
    "    print(\"\\nHighly Correlated Feature Pairs (|correlation| > 0.8):\")\n",
    "    for feat1, feat2, corr in high_corr:\n",
    "        print(f\"{feat1} - {feat2}: {corr:.3f}\")\n",
    "\n",
    "\n",
    "analyze_correlations()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "16cd909972c3789c",
   "metadata": {},
   "source": [
    "# Feature Importance Analysis\n",
    "def analyze_feature_importance(target_col='renewable_generation'):  # Changed from 'renewable_share'\n",
    "    \"\"\"Analyze feature importance using mutual information\"\"\"\n",
    "\n",
    "    # First, verify target column exists\n",
    "    if target_col not in df.columns:\n",
    "        print(f\"Warning: {target_col} not found. Available columns:\")\n",
    "        print(df.columns)\n",
    "        return None\n",
    "\n",
    "    # Prepare data\n",
    "    X = df.select_dtypes(include=[np.number]).drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "\n",
    "    # Handle NaN values\n",
    "    data = pd.concat([X, y], axis=1)\n",
    "    data = data.dropna()\n",
    "\n",
    "    X = data.drop(columns=[target_col])\n",
    "    y = data[target_col]\n",
    "\n",
    "    # Calculate mutual information scores\n",
    "    mi_scores = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create importance DataFrame\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': mi_scores\n",
    "    }).sort_values('importance', ascending=False)\n",
    "\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = Path('figures/feature_analysis')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Plot feature importance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.barplot(data=importance_df, x='importance', y='feature')\n",
    "    plt.title(f'Feature Importance for {target_col} (Mutual Information)')\n",
    "    plt.xlabel('Mutual Information Score')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(analysis_dir / 'feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return importance_df\n",
    "\n",
    "\n",
    "# Run feature importance analysis\n",
    "print(\"Available columns in dataset:\")\n",
    "print(df.columns)\n",
    "importance_results = analyze_feature_importance('renewable_generation')\n",
    "print(\"\\nFeature Importance Rankings:\")\n",
    "display(importance_results)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fedc9dd480683e2d",
   "metadata": {},
   "source": [
    "# Time Series Feature Analysis\n",
    "def analyze_temporal_features():\n",
    "    \"\"\"Analyze temporal features and their relationships\"\"\"\n",
    "\n",
    "    # Plot time series features\n",
    "    temporal_features = [col for col in df.columns if 'lag' in col or 'rolling' in col]\n",
    "\n",
    "    if temporal_features:\n",
    "        # Create line plots for lag features\n",
    "        lag_features = [col for col in temporal_features if 'lag' in col]\n",
    "        if lag_features:\n",
    "            fig = go.Figure()\n",
    "            for col in lag_features:\n",
    "                fig.add_trace(go.Scatter(x=df.index, y=df[col], name=col))\n",
    "            fig.update_layout(title='Lag Features Over Time')\n",
    "            fig.write_image(str(analysis_dir / 'lag_features.png'))\n",
    "            fig.show()\n",
    "\n",
    "        # Create line plots for rolling features\n",
    "        rolling_features = [col for col in temporal_features if 'rolling' in col]\n",
    "        if rolling_features:\n",
    "            fig = go.Figure()\n",
    "            for col in rolling_features:\n",
    "                fig.add_trace(go.Scatter(x=df.index, y=df[col], name=col))\n",
    "            fig.update_layout(title='Rolling Features Over Time')\n",
    "            fig.write_image(str(analysis_dir / 'rolling_features.png'))\n",
    "            fig.show()\n",
    "\n",
    "    # Analyze autocorrelation\n",
    "    if 'renewable_generation' in df.columns:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        pd.plotting.autocorrelation_plot(df['renewable_generation'])\n",
    "        plt.title('Autocorrelation Plot of Renewable Generation')\n",
    "        plt.savefig(analysis_dir / 'autocorrelation.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "analyze_temporal_features()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "57c4d4ecdd159f96",
   "metadata": {},
   "source": [
    "# Geographic Feature Analysis\n",
    "def analyze_geographic_features():\n",
    "    \"\"\"Analyze geographic features and regional patterns\"\"\"\n",
    "\n",
    "    if 'country' in df.columns and 'renewable_share' in df.columns:\n",
    "        # Calculate regional statistics\n",
    "        regional_stats = df.groupby('country').agg({\n",
    "            'renewable_share': ['mean', 'std', 'min', 'max'],\n",
    "            'total_renewable': ['mean', 'std']\n",
    "        }).round(3)\n",
    "\n",
    "        # Plot regional patterns\n",
    "        fig = px.choropleth(\n",
    "            df,\n",
    "            locations='country',\n",
    "            color='renewable_generation',\n",
    "            title='Geographic Distribution of Renewable Generation',\n",
    "            color_continuous_scale='Viridis'\n",
    "        )\n",
    "        fig.write_image(str(analysis_dir / 'geographic_distribution.png'))\n",
    "        fig.show()\n",
    "\n",
    "        # Display regional statistics\n",
    "        print(\"\\nRegional Statistics:\")\n",
    "        display(regional_stats)\n",
    "\n",
    "\n",
    "analyze_geographic_features()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "cbce943763a1dcd3",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "def perform_pca_analysis():\n",
    "    \"\"\"Perform PCA on numerical features\"\"\"\n",
    "\n",
    "    # Prepare data\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    X = df[numeric_cols]\n",
    "\n",
    "    # Handle NaN values\n",
    "    X = X.dropna(axis=0)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Perform PCA\n",
    "    pca = PCA()\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    # Calculate explained variance ratio\n",
    "    explained_variance = pca.explained_variance_ratio_\n",
    "    cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "    # Plot explained variance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(range(1, len(explained_variance) + 1), cumulative_variance, 'bo-')\n",
    "    plt.axhline(y=0.95, color='r', linestyle='--')\n",
    "    plt.xlabel('Number of Components')\n",
    "    plt.ylabel('Cumulative Explained Variance Ratio')\n",
    "    plt.title('PCA Explained Variance')\n",
    "    plt.savefig(analysis_dir / 'pca_explained_variance.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    # Print component loadings\n",
    "    components_df = pd.DataFrame(\n",
    "        pca.components_.T,\n",
    "        columns=[f'PC{i + 1}' for i in range(len(pca.components_))],\n",
    "        index=numeric_cols\n",
    "    )\n",
    "\n",
    "    print(\"\\nPrincipal Component Loadings:\")\n",
    "    display(components_df)\n",
    "\n",
    "    return pca, components_df\n",
    "\n",
    "\n",
    "pca_results = perform_pca_analysis()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "64b635ab595f945",
   "metadata": {},
   "source": [
    "# Feature Interaction Analysis\n",
    "def analyze_feature_interactions(df: pd.DataFrame):\n",
    "    \"\"\"Analyze interactions between important features\"\"\"\n",
    "    # Use actual columns instead of relying on importance results\n",
    "    feature_cols = [\n",
    "        'Hydroelectric Power',\n",
    "        'Solar Energy',\n",
    "        'Wind Energy',\n",
    "        'Geothermal Energy',\n",
    "        'Biomass Energy'\n",
    "    ]\n",
    "\n",
    "    # Create scatter matrix\n",
    "    fig = px.scatter_matrix(\n",
    "        df[feature_cols],\n",
    "        dimensions=feature_cols,\n",
    "        title='Feature Interactions Matrix'\n",
    "    )\n",
    "    fig.write_image(str(analysis_dir / 'feature_interactions.png'))\n",
    "    fig.show()\n",
    "\n",
    "    # Calculate interaction terms\n",
    "    for i in range(len(feature_cols) - 1):\n",
    "        for j in range(i + 1, len(feature_cols) - 1):\n",
    "            feat1, feat2 = feature_cols[i], feature_cols[j]\n",
    "            interaction_name = f'{feat1}_{feat2}_interaction'\n",
    "            df[interaction_name] = df[feat1] * df[feat2]\n",
    "\n",
    "    # Create correlation matrix with interactions\n",
    "    corr_matrix = df.corr()\n",
    "\n",
    "    # Plot correlation heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', center=0)\n",
    "    plt.title('Feature and Interaction Correlations')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(analysis_dir / 'interaction_correlations.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    return corr_matrix\n",
    "\n",
    "\n",
    "# Run the analysis\n",
    "interaction_results = analyze_feature_interactions(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9c1dd7ee65756ed",
   "metadata": {},
   "source": [
    "# Summary and Recommendations\n",
    "def generate_feature_summary():\n",
    "    \"\"\"Generate summary of feature analysis and recommendations\"\"\"\n",
    "\n",
    "    summary = \"\"\"\n",
    "    Feature Analysis Summary:\n",
    "    \n",
    "    1. Distribution Analysis:\n",
    "    - Identified non-normal distributions in several features\n",
    "    - Log transformation recommended for skewed features\n",
    "    - Some features show clear outliers\n",
    "    \n",
    "    2. Correlation Analysis:\n",
    "    - Several highly correlated feature pairs identified\n",
    "    - Consider feature selection or dimensionality reduction\n",
    "    - Watch for multicollinearity in modeling\n",
    "    \n",
    "    3. Feature Importance:\n",
    "    - Top features identified through mutual information\n",
    "    - Economic indicators show strong predictive power\n",
    "    - Weather features show moderate importance\n",
    "    \n",
    "    4. Temporal Features:\n",
    "    - Lag features capture historical patterns\n",
    "    - Rolling features smooth out noise\n",
    "    - Strong autocorrelation present\n",
    "    \n",
    "    5. Geographic Analysis:\n",
    "    - Clear regional patterns in renewable adoption\n",
    "    - Significant variation between countries\n",
    "    - Consider regional clustering\n",
    "    \n",
    "    6. PCA Analysis:\n",
    "    - First few components explain majority of variance\n",
    "    - Consider dimensionality reduction\n",
    "    - Important feature combinations identified\n",
    "    \n",
    "    Recommendations:\n",
    "    1. Feature Selection:\n",
    "    - Remove highly correlated features\n",
    "    - Focus on top important features\n",
    "    - Consider PCA for dimensionality reduction\n",
    "    \n",
    "    2. Feature Engineering:\n",
    "    - Create interaction terms for top features\n",
    "    - Log transform skewed features\n",
    "    - Standardize numerical features\n",
    "    \n",
    "    3. Modeling Considerations:\n",
    "    - Handle temporal autocorrelation\n",
    "    - Account for geographic patterns\n",
    "    - Consider hierarchical modeling\n",
    "    \n",
    "    4. Additional Features:\n",
    "    - Create policy impact indicators\n",
    "    - Add economic interaction terms\n",
    "    - Develop regional benchmarks\n",
    "    \"\"\"\n",
    "\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(f\"<pre>{summary}</pre>\"))\n",
    "\n",
    "\n",
    "generate_feature_summary()"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
